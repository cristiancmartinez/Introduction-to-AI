{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human Activity Recognition using Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ex2_helper as helper\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and preprocess the HAR data: Human Activity Recognition Using Smartphones Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = helper.separate_subjects(*helper.load_data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the original 6-class labels into a binary (active vs. inactive) problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.apply(helper.to_binary_label)\n",
    "y_test = y_test.apply(helper.to_binary_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data in y_train is imbalanced, as 0 -> 4067 and 1 -> 3285 samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Train baseline SVM models with different kernels (linear, polynomial, RBF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 43 candidates, totalling 129 fits\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "('scaler', StandardScaler()), \n",
    "('pca', PCA(n_components= 2)),\n",
    "('svc', SVC(class_weight='balanced'))\n",
    "])\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'svc__kernel': ['linear'],\n",
    "        'svc__C': [0.1, 1, 10, 100]\n",
    "    },\n",
    "    {\n",
    "        'svc__kernel': ['poly'],\n",
    "        'svc__C': [0.1, 1, 10, 100],\n",
    "        'svc__degree': [2, 3],\n",
    "        'svc__gamma': [0.001, 0.01, 0.1]\n",
    "    },\n",
    "    {\n",
    "        'svc__kernel': ['rbf'],\n",
    "        'svc__C': [0.1, 1, 10, 100],\n",
    "        'svc__gamma': [0.001, 0.01, 0.1]\n",
    "    },{\n",
    "        'svc__kernel': ['sigmoid'],\n",
    "        'svc__gamma': [0.001, 0.01, 0.1]\n",
    "    },\n",
    "]\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1',\n",
    "    cv=3,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best parameters from GridSearchCV:\", grid_search.best_params_)\n",
    "print(\"Best cross-validation F1 score:\", grid_search.best_score_)\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "f1_best = metrics.f1_score(y_test, y_pred, average=None)\n",
    "cm_best = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(\"Test set evaluation for the best model:\")\n",
    "print(\"F1 Score:\", f1_best)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "4. Perform hyperparameter tuning using GridSearchCV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "5. Evaluate and interpret results using confusion matrices and classification metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Reduce the test data to 2 dimensions (for visualization)\n",
    "pca = PCA(n_components=2)\n",
    "X_test_pca = pca.fit_transform(X_test)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=X_test_pca[:, 0], y=X_test_pca[:, 1], \n",
    "                hue=y_test.map({0: \"Inactive\", 1: \"Active\"}),\n",
    "                palette=\"Set1\")\n",
    "plt.title(\"PCA Projection of Test Data\")\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.legend(title=\"Activity\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert the CV results to a DataFrame for easy filtering\n",
    "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "# Iterate over each kernel type and find the best configuration\n",
    "for kernel in ['linear', 'poly', 'rbf', 'sigmoid']:\n",
    "    kernel_results = cv_results[cv_results['param_svc__kernel'] == kernel]\n",
    "\n",
    "    best_idx = kernel_results['mean_test_score'].idxmax()\n",
    "    best_params = cv_results.loc[best_idx, 'params']\n",
    "    best_score = cv_results.loc[best_idx, 'mean_test_score']\n",
    "    best_time = cv_results.loc[best_idx, 'mean_fit_time']\n",
    "\n",
    "    print(f\"Best configuration for kernel '{kernel}':\")\n",
    "    print(f\"  Parameters: {best_params}\")\n",
    "    print(f\"  Mean CV F1 Score: {best_score:.4f}\")\n",
    "    print(f\"  Mean CV time: {best_time:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Convert the CV results to a DataFrame\n",
    "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(\n",
    "    data=cv_results, \n",
    "    x='mean_fit_time', \n",
    "    y='mean_test_score', \n",
    "    hue='param_svc__kernel',\n",
    "    s=50\n",
    ")\n",
    "plt.title(\"Relationship Between Time Taken and Accuracy for All Kernels\")\n",
    "plt.xlabel(\"Mean Fit Time (seconds)\")\n",
    "plt.ylabel(\"Mean CV F1 Score\")\n",
    "plt.legend(title=\"Kernel\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
